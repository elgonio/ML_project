{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "reads in a csv file, converts labels into the correct form\n",
    "then splits the labels from the data and returns 2 seperate arrays\n",
    "\"\"\"\n",
    "def load_file(filename):\n",
    "    data = np.genfromtxt(filename,delimiter=',')\n",
    "    # convert the labels into the correct form\n",
    "    #for row in data:\n",
    "    #    if row[0] == -1.0:\n",
    "    #        row[0] = 0\n",
    "    #    elif row[0] == 1.0:\n",
    "    #        row[0] = 1\n",
    "            \n",
    "\n",
    "    # y is the first column i.e the labels\n",
    "    y = data[:,0]\n",
    "    # X is the remainder of the data\n",
    "    X = data[:,2:]\n",
    " \n",
    "    return y,X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = load_file(\"dota2Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_values(column,X):\n",
    "    data = X\n",
    "\n",
    "    print(\"processing...\")\n",
    "    values = dict()\n",
    "    for val in data.T[column]:\n",
    "        if val in values.keys():\n",
    "            values[val] += 1\n",
    "        else:\n",
    "            values[val] = 1\n",
    "        \n",
    "    x, y = zip(*sorted(values.items(), key=lambda x: x[0]))\n",
    "    plt.bar(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X[:,0] = y\n",
    "count_values(0,X)\n",
    "#count_values(1,X)\n",
    "#count_values(2,X)\n",
    "#count_values(3,X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "115\n",
      "norm: 6.105115921485573\n",
      "training...\n",
      "split is : 48782 43868 0.5265191581219644\n",
      "iteration: 1  cost: 69279.55134715776   diff: 6.370760236655304   accuracy: 0.4888397193739881\n",
      "split is : 48782 43868 0.5265191581219644\n",
      "iteration: 2  cost: 69279.55134715776   diff: 4.805323465791478e-16   accuracy: 0.4888397193739881\n",
      "____________________________________________________________________________________________________________\n",
      "split is : 48782 43868 0.5265191581219644\n",
      "final iteration: 2  cost: 69279.55134715776   diff: 4.805323465791478e-16   accuracy: 0.4888397193739881\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "class logistic_regressor():\n",
    "    # reguralisation factor\n",
    "    l = 0.05\n",
    "\n",
    "    step_size = 0.03\n",
    "    #accuracy = 0\n",
    "\n",
    "    def __init__(self,filename,testfile):\n",
    "        self.data = np.genfromtxt(filename,delimiter=',')\n",
    "        # convert the labels into the correct form\n",
    "        for row in self.data:\n",
    "            if row[0] == -1:\n",
    "                row[0] = 0\n",
    "            \n",
    "       \n",
    "        # we add in a column of ones as theta 0\n",
    "        \n",
    "        b = np.ones((self.data.shape[0],self.data.shape[1]+1-3))\n",
    "        b[:,1:] = np.delete(self.data,[1,2,3],1)\n",
    "        b[:,[0,1]] = b[:,[1,0]]\n",
    "        self.data = b\n",
    "        \n",
    "        self.test_data = np.genfromtxt(testfile,delimiter=',')\n",
    "        # convert the labels into the correct form\n",
    "        for row in self.test_data:\n",
    "            if row[0] == -1:\n",
    "                row[0] = 0\n",
    "            \n",
    "       \n",
    "        # we add in a column of ones as theta 0\n",
    "        \n",
    "        b = np.ones((self.test_data.shape[0],self.test_data.shape[1]+1-3))\n",
    "        b[:,1:] = np.delete(self.test_data,[1,2,3],1)\n",
    "        b[:,[0,1]] = b[:,[1,0]]\n",
    "        self.test_data = b\n",
    "        \n",
    "        print(self.data[:10])\n",
    "        print(self.data.shape[1])\n",
    "\n",
    "        self.num_rows = self.data.shape[0]\n",
    "        # we don't count the labels or params as part of the columns\n",
    "        self.num_cols = self.data.shape[1]-2\n",
    "        self.init_params()\n",
    "        print(\"norm:\",np.linalg.norm(self.params))\n",
    "\n",
    "    def sigmoid(self,z):\n",
    "        result = 1/(1+np.exp(-z))\n",
    "        return result\n",
    "\n",
    "    def sigmoid_deriv(self,z):\n",
    "        result = self.sigmoid(z) * (1-self.sigmoid(z))\n",
    "        return result\n",
    "\n",
    "        #s = sigmoid(z)\n",
    "        #return s * (1-s)\n",
    "\n",
    "    def init_params(self):\n",
    "        # generates an array of numbers in the range [0,1]\n",
    "        self.params = np.random.rand(self.num_cols)\n",
    "        # we want the params in the range [-1,1]\n",
    "        self.params = self.params*2-1\n",
    "\n",
    "        self.params *= 1\n",
    "\n",
    "    def cost(self):\n",
    "        result = 0\n",
    "        for row in self.data:\n",
    "            y = row[0]\n",
    "            d_product = np.dot(self.params,row[2:])\n",
    "            h_theta = self.sigmoid(d_product)\n",
    "            #print(\"cost: d_product =\", d_product, \"h_theta = \", h_theta)\n",
    "            # we get bugs if h_theta is exactly 1 or 0\n",
    "            if h_theta == 1:\n",
    "                h_theta = 1-10e-5\n",
    "            elif h_theta == 0:\n",
    "                h_theta = 10e-5\n",
    "\n",
    "            #print(\"h_theta:\", h_theta, \"label:\", y)\n",
    "            \n",
    "            temp = y*np.log(h_theta) + (1-y)*np.log(1-h_theta) \n",
    "            \n",
    "            result = result + temp \n",
    "\n",
    "        result = -result + self.l*np.sum(np.square(row)) \n",
    "        return result\n",
    "\n",
    "    def MSE(self):\n",
    "        count = 0\n",
    "        total = 0\n",
    "        for row in self.data:\n",
    "            label = row[0]\n",
    "            d_product = np.dot(self.params,row[2:])\n",
    "            h_theta = self.sigmoid(d_product)\n",
    "            if h_theta > 0:\n",
    "                prediction = 1\n",
    "            else:\n",
    "                prediction = 0\n",
    "\n",
    "            if prediction == label:\n",
    "                count = count + 1\n",
    "\n",
    "            total = total + (h_theta - label)**2\n",
    "\n",
    "        #self.accuracy = count/self.num_rows\n",
    "\n",
    "        total = (1/2*self.num_rows)*total\n",
    "\n",
    "        return total\n",
    "\n",
    "\n",
    "\n",
    "    def gradient_descent(self):\n",
    "        \n",
    "        for row in self.data:\n",
    "            old_params = self.params+0\n",
    "            y = row[0]\n",
    "\n",
    "            h_theta = self.sigmoid(np.dot(old_params,row[2:]))\n",
    "\n",
    "            new_params = np.zeros_like(self.params)\n",
    "            new_params[0] = old_params[0] - self.step_size*(self.sigmoid(h_theta) - row[0])\n",
    "            \n",
    "            for k in range(1,self.num_cols):\n",
    "                self.params[k] = old_params[k] - self.step_size * ((h_theta-y)*row[k] + self.l*old_params[k])\n",
    "            \n",
    "    def train(self,tol):\n",
    "        print(\"training...\")\n",
    "        diff = tol*10\n",
    "\n",
    "        iteration_num = 0\n",
    "\n",
    "        while diff > tol :\n",
    "            old_params = self.params + 0\n",
    "\n",
    "            self.gradient_descent()\n",
    "\n",
    "            iteration_num = iteration_num + 1\n",
    "            diff = np.linalg.norm(self.params-old_params)\n",
    "\n",
    "            if iteration_num % 1 == 0:\n",
    "\n",
    "                print(\"iteration:\", iteration_num,\" cost:\", self.cost(), \"  diff:\", diff,\"  accuracy:\", self.accuracy())\n",
    "            \n",
    "        print(\"____________________________________________________________________________________________________________\")\n",
    "        print(\"final iteration:\", iteration_num,\" cost:\", self.cost(), \"  diff:\", diff,\"  accuracy:\", self.accuracy())\n",
    "\n",
    "            #print(\"prediction:\", prediction, \"actual\", label)\n",
    "\n",
    "\n",
    "    def accuracy(self):\n",
    "        count = 0\n",
    "        split_count = 0\n",
    "        for row in self.data:\n",
    "\n",
    "            label = row[0]\n",
    "\n",
    "            if label == 1:\n",
    "                split_count = split_count + 1\n",
    "\n",
    "            prediction = self.sigmoid(np.dot(self.params,row[2:]))\n",
    "            if prediction > 0.5:\n",
    "                prediction = 1\n",
    "            else:\n",
    "                prediction = 0\n",
    "\n",
    "            if prediction == label:\n",
    "                count = count + 1\n",
    "\n",
    "        print(\"split is :\",split_count,self.data.shape[0]-split_count, split_count/self.data.shape[0])\n",
    "        #self.accuracy = count/self.data.shape[0]\n",
    "        return count/self.num_rows\n",
    "    \n",
    "    def test_accuracy(self):\n",
    "        count = 0\n",
    "        split_count = 0\n",
    "        for row in self.test_data:\n",
    "\n",
    "            label = row[0]\n",
    "\n",
    "            if label == 1:\n",
    "                split_count = split_count + 1\n",
    "\n",
    "            prediction = self.sigmoid(np.dot(self.params,row[2:]))\n",
    "            if prediction > 0.5:\n",
    "                prediction = 1\n",
    "            else:\n",
    "                prediction = 0\n",
    "\n",
    "            if prediction == label:\n",
    "                count = count + 1\n",
    "\n",
    "        print(\"split is :\",split_count,self.test_data.shape[0]-split_count, split_count/self.test_data.shape[0])\n",
    "        #self.accuracy = count/self.data.shape[0]\n",
    "        return count/self.test_data.shape[0]\n",
    "    \n",
    "    def predict_sample(self,size):\n",
    "        count = 0\n",
    "        split_count = 0\n",
    "        for k in range(size):         \n",
    "            row = self.data[np.random.randint(0,self.test_data.shape[0])]\n",
    "\n",
    "            label = row[0]\n",
    "\n",
    "            if label == 1:\n",
    "                split_count = split_count + 1\n",
    "\n",
    "            prediction = self.sigmoid(np.dot(self.params,row[2:]))\n",
    "            if prediction > 0.5:\n",
    "                prediction = 1\n",
    "            else:\n",
    "                prediction = 0\n",
    "\n",
    "            if prediction == label:\n",
    "                count = count + 1\n",
    "                \n",
    "            print(\"prediction: \", prediction,\" truth: \",label)\n",
    "            \n",
    "    def alt_predict_sample(self,size):\n",
    "        count = 0\n",
    "        split_count = 0\n",
    "        for k in range(size):         \n",
    "            row = self.data[np.random.randint(0,self.test_data.shape[0])]\n",
    "\n",
    "            label = row[0]\n",
    "\n",
    "            if label == 1:\n",
    "                split_count = split_count + 1\n",
    "\n",
    "            prediction = self.sigmoid(np.dot(self.params,row[2:]))\n",
    "            if prediction > 0.5:\n",
    "                prediction = 0\n",
    "            else:\n",
    "                prediction = 1\n",
    "\n",
    "            if prediction == label:\n",
    "                count = count + 1\n",
    "                \n",
    "            print(\"prediction: \", prediction,\" truth: \",label)\n",
    "            \n",
    "    def confusion_matrix(self):\n",
    "        count = 0\n",
    "        split_count = 0\n",
    "        true_pos = 0\n",
    "        true_neg = 0\n",
    "        false_pos = 0\n",
    "        false_neg = 0\n",
    "        \n",
    "        for row in self.test_data:        \n",
    "            label = row[0]\n",
    "\n",
    "            prediction = self.sigmoid(np.dot(self.params,row[2:]))\n",
    "            if prediction > 0.5:\n",
    "                prediction = 1\n",
    "            else:\n",
    "                prediction = 0\n",
    "\n",
    "            if prediction == label and label == 1:\n",
    "                true_pos += 1\n",
    "            elif prediction == 0 and label == 0:\n",
    "                true_neg += 1\n",
    "            elif prediction == 0 and label == 1:\n",
    "                false_neg += 1\n",
    "            elif prediction == 1 and label == 0:\n",
    "                false_pos += 1\n",
    "                \n",
    "        print(\"true_pos: \", true_pos,\" false_pos: \",false_pos)\n",
    "        print(\"false_neg: \", false_neg,\" true_neg: \",true_neg)\n",
    "\n",
    "\n",
    "lr = logistic_regressor(\"dota2Train.csv\",\"dota2Test.csv\")\n",
    "lr.train(10e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split is : 48782 43868 0.5265191581219644\n",
      "accuracy on seen data is: 0.48977873718294657\n",
      "split is : 5502 4792 0.5344861084126675\n",
      "accuracy on unseen data is: 0.4655138915873324\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy on seen data is:\", lr.accuracy())\n",
    "print(\"accuracy on unseen data is:\", lr.test_accuracy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:  1  truth:  0.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  0  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  0  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  0  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  0  truth:  0.0\n",
      "prediction:  1  truth:  0.0\n"
     ]
    }
   ],
   "source": [
    "lr.predict_sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_pos:  2673  false_pos:  2505\n",
      "false_neg:  2829  true_neg:  2287\n"
     ]
    }
   ],
   "source": [
    "lr.confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
