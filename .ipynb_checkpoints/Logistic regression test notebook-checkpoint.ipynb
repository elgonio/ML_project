{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "reads in a csv file, converts labels into the correct form\n",
    "then splits the labels from the data and returns 2 seperate arrays\n",
    "\"\"\"\n",
    "def load_file(filename):\n",
    "    data = np.genfromtxt(filename,delimiter=',')\n",
    "    # convert the labels into the correct form\n",
    "    #for row in data:\n",
    "    #    if row[0] == -1.0:\n",
    "    #        row[0] = 0\n",
    "    #    elif row[0] == 1.0:\n",
    "    #        row[0] = 1\n",
    "            \n",
    "\n",
    "    # y is the first column i.e the labels\n",
    "    y = data[:,0]\n",
    "    # X is the remainder of the data\n",
    "    X = data[:,2:]\n",
    " \n",
    "    return y,X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = load_file(\"dota2Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_values(column,X):\n",
    "    data = X\n",
    "\n",
    "    print(\"processing...\")\n",
    "    values = dict()\n",
    "    for val in data.T[column]:\n",
    "        if val in values.keys():\n",
    "            values[val] += 1\n",
    "        else:\n",
    "            values[val] = 1\n",
    "        \n",
    "    x, y = zip(*sorted(values.items(), key=lambda x: x[0]))\n",
    "    plt.bar(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#count_values(0,X)\n",
    "#count_values(1,X)\n",
    "#count_values(2,X)\n",
    "count_values(3,X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "115\n",
      "norm: 6.50077777006181\n",
      "training...\n",
      "split is : 48782 43868 0.5265191581219644\n",
      "iteration: 1  cost: 64169.76490842841   diff: 6.496814134224562   accuracy: 0.5250620615218564\n",
      "split is : 48782 43868 0.5265191581219644\n",
      "iteration: 2  cost: 64169.76490842841   diff: 1.3877775131508763e-41   accuracy: 0.5250620615218564\n",
      "____________________________________________________________________________________________________________\n",
      "split is : 48782 43868 0.5265191581219644\n",
      "final iteration: 2  cost: 64169.76490842841   diff: 1.3877775131508763e-41   accuracy: 0.5250620615218564\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "class logistic_regressor():\n",
    "    # reguralisation factor\n",
    "    l = 1\n",
    "\n",
    "    step_size = 0.001\n",
    "    #accuracy = 0\n",
    "\n",
    "    def __init__(self,filename,testfile):\n",
    "        self.data = np.genfromtxt(filename,delimiter=',')\n",
    "        # convert the labels into the correct form\n",
    "        for row in self.data:\n",
    "            if row[0] == -1:\n",
    "                row[0] = 0\n",
    "            \n",
    "       \n",
    "        # we add in a column of ones as theta 0\n",
    "        \n",
    "        b = np.ones((self.data.shape[0],self.data.shape[1]+1-3))\n",
    "        b[:,1:] = np.delete(self.data,[1,2,3],1)\n",
    "        b[:,[0,1]] = b[:,[1,0]]\n",
    "        self.data = b\n",
    "        \n",
    "        self.test_data = np.genfromtxt(filename,delimiter=',')\n",
    "        # convert the labels into the correct form\n",
    "        for row in self.test_data:\n",
    "            if row[0] == -1:\n",
    "                row[0] = 0\n",
    "            \n",
    "       \n",
    "        self.init_params()\n",
    "        \n",
    "        # we add in a column of ones as theta 0\n",
    "        \n",
    "        b = np.ones((self.test_data.shape[0],self.test_data.shape[1]+1-3))\n",
    "        b[:,1:] = np.delete(self.test_data,[1,2,3],1)\n",
    "        b[:,[0,1]] = b[:,[1,0]]\n",
    "        self.test_data = b\n",
    "        \n",
    "        print(self.data[:10])\n",
    "        print(self.data.shape[1])\n",
    "\n",
    "        self.num_rows = self.data.shape[0]\n",
    "        # we don't count the labels as part of the columns\n",
    "        self.num_cols = self.data.shape[1]-1\n",
    "        print(\"norm:\",np.linalg.norm(self.params))\n",
    "\n",
    "    def sigmoid(self,z):\n",
    "        result = 1/(1+np.exp(-z))\n",
    "        return result\n",
    "\n",
    "    def sigmoid_deriv(self,z):\n",
    "        result = self.sigmoid(z) * (1-self.sigmoid(z))\n",
    "        return result\n",
    "\n",
    "        #s = sigmoid(z)\n",
    "        #return s * (1-s)\n",
    "\n",
    "    def init_params(self):\n",
    "        # generates an array of numbers in the range [0,1]\n",
    "        self.params = np.random.rand(self.num_cols)\n",
    "        # we want the params in the range [-1,1]\n",
    "        self.params = self.params*2-1\n",
    "\n",
    "        self.params *= 1\n",
    "\n",
    "    def cost(self):\n",
    "        result = 0\n",
    "        for row in self.data:\n",
    "            y = row[0]\n",
    "            d_product = np.dot(self.params,row[1:])\n",
    "            h_theta = self.sigmoid(d_product)\n",
    "            #print(\"cost: d_product =\", d_product, \"h_theta = \", h_theta)\n",
    "            # we get bugs if h_theta is exactly 1 or 0\n",
    "            if h_theta == 1:\n",
    "                h_theta = 1-10e-5\n",
    "            elif h_theta == 0:\n",
    "                h_theta = 10e-5\n",
    "\n",
    "            #print(\"h_theta:\", h_theta, \"label:\", y)\n",
    "            \n",
    "            temp = (y*np.log(h_theta) + (1-y)*np.log(1-h_theta)) \n",
    "            \n",
    "            result = result - temp \n",
    "\n",
    "        result = result + self.l*np.sum(np.square(row)) \n",
    "        return result\n",
    "\n",
    "    def MSE(self):\n",
    "        count = 0\n",
    "        total = 0\n",
    "        for row in self.data:\n",
    "            label = row[0]\n",
    "            d_product = np.dot(self.params,row[1:])\n",
    "            h_theta = self.sigmoid(d_product)\n",
    "            if h_theta > 0:\n",
    "                prediction = 1\n",
    "            else:\n",
    "                prediction = 0\n",
    "\n",
    "            if prediction == label:\n",
    "                count = count + 1\n",
    "\n",
    "            total = total + (h_theta - label)**2\n",
    "\n",
    "        #self.accuracy = count/self.num_rows\n",
    "\n",
    "        total = (1/2*self.num_rows)*total\n",
    "\n",
    "        return total\n",
    "\n",
    "\n",
    "\n",
    "    def gradient_descent(self):\n",
    "        \n",
    "        for row in self.data:\n",
    "            old_params = self.params+0\n",
    "            y = row[0]\n",
    "\n",
    "            h_theta = self.sigmoid(np.dot(old_params,row[1:]))\n",
    "\n",
    "            new_params = np.zeros_like(self.params)\n",
    "            new_params[0] = old_params[0] - self.step_size*self.sigmoid(h_theta) - row[0]\n",
    "            \n",
    "            for k in range(1,self.num_cols):\n",
    "                self.params[k] = old_params[k] - self.step_size * ((h_theta-y)*row[k] + self.l*old_params[k])\n",
    "            \n",
    "    def train(self,tol):\n",
    "        print(\"training...\")\n",
    "        diff = tol*10\n",
    "\n",
    "        iteration_num = 0\n",
    "\n",
    "        while diff > tol :\n",
    "            old_params = self.params + 0\n",
    "\n",
    "            self.gradient_descent()\n",
    "\n",
    "            iteration_num = iteration_num + 1\n",
    "            diff = np.linalg.norm(self.params-old_params)\n",
    "\n",
    "            if iteration_num % 1 == 0:\n",
    "\n",
    "                print(\"iteration:\", iteration_num,\" cost:\", self.cost(), \"  diff:\", diff,\"  accuracy:\", self.accuracy())\n",
    "            \n",
    "        print(\"____________________________________________________________________________________________________________\")\n",
    "        print(\"final iteration:\", iteration_num,\" cost:\", self.cost(), \"  diff:\", diff,\"  accuracy:\", self.accuracy())\n",
    "        for row in self.data:\n",
    "            label = row[0]\n",
    "            prediction = self.sigmoid(np.dot(self.params,row[1:]))\n",
    "            if prediction > 0.5:\n",
    "                prediction = 1\n",
    "            else:\n",
    "                prediction = 0\n",
    "\n",
    "            #print(\"prediction:\", prediction, \"actual\", label)\n",
    "\n",
    "\n",
    "    def accuracy(self):\n",
    "        count = 0\n",
    "        split_count = 0\n",
    "        for row in self.data:\n",
    "\n",
    "            label = row[0]\n",
    "\n",
    "            if label == 1:\n",
    "                split_count = split_count + 1\n",
    "\n",
    "            prediction = self.sigmoid(np.dot(self.params,row[2:]))\n",
    "            if prediction > 0.5:\n",
    "                prediction = 1\n",
    "            else:\n",
    "                prediction = 0\n",
    "\n",
    "            if prediction == label:\n",
    "                count = count + 1\n",
    "\n",
    "        print(\"split is :\",split_count,self.data.shape[0]-split_count, split_count/self.data.shape[0])\n",
    "        #self.accuracy = count/self.data.shape[0]\n",
    "        return count/self.num_rows\n",
    "    \n",
    "    def test_accuracy(self):\n",
    "        count = 0\n",
    "        split_count = 0\n",
    "        for row in self.test_data:\n",
    "\n",
    "            label = row[0]\n",
    "\n",
    "            if label == 1:\n",
    "                split_count = split_count + 1\n",
    "\n",
    "            prediction = self.sigmoid(np.dot(self.params,row[2:]))\n",
    "            if prediction > 0.5:\n",
    "                prediction = 1\n",
    "            else:\n",
    "                prediction = 0\n",
    "\n",
    "            if prediction == label:\n",
    "                count = count + 1\n",
    "\n",
    "        print(\"split is :\",split_count,self.data.shape[0]-split_count, split_count/self.data.shape[0])\n",
    "        #self.accuracy = count/self.data.shape[0]\n",
    "        return count/self.num_rows\n",
    "    \n",
    "    def predict_sample(self,size):\n",
    "        count = 0\n",
    "        split_count = 0\n",
    "        for k in range(size):         \n",
    "            row = self.data[np.random.randint(0,self.data.shape[0])]\n",
    "\n",
    "            label = row[0]\n",
    "\n",
    "            if label == 1:\n",
    "                split_count = split_count + 1\n",
    "\n",
    "            prediction = self.sigmoid(np.dot(self.params,row[1:]))\n",
    "            if prediction > 0.5:\n",
    "                prediction = 1\n",
    "            else:\n",
    "                prediction = 0\n",
    "\n",
    "            if prediction == label:\n",
    "                count = count + 1\n",
    "                \n",
    "            print(\"prediction: \", prediction,\" truth: \",label)\n",
    "\n",
    "\n",
    "lr = logistic_regressor(\"dota2Train.csv\")\n",
    "lr.train(10e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  0  truth:  0.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  0  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  0  truth:  0.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  0  truth:  0.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  0  truth:  1.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  0  truth:  0.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  0  truth:  0.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  0  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  0  truth:  0.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  0  truth:  0.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  0  truth:  0.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  0  truth:  0.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  0  truth:  0.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  0  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  0  truth:  0.0\n",
      "prediction:  0  truth:  1.0\n",
      "prediction:  0  truth:  0.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  0  truth:  0.0\n",
      "prediction:  0  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  0  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  0  truth:  0.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  0  truth:  0.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  1  truth:  1.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  1  truth:  0.0\n",
      "prediction:  0  truth:  0.0\n"
     ]
    }
   ],
   "source": [
    "lr.predict_sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
